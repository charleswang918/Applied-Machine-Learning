{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "60IUi_PWi8DD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "NvFNcKlfjBBD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(rawtrain_X, rawtrain_y), (rawtest_X, rawtest_y) = fashion_mnist.load_data()\n",
    "print(\"The shape of the training iamges are:\", rawtrain_X.shape)\n",
    "print(\"The shape of the training labels are:\", rawtrain_y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJX4KKCFjBgk",
    "outputId": "24724bc3-f11e-4d09-b333-06e874819192",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of the training iamges are: (60000, 28, 28)\n",
      "The shape of the training labels are: (60000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"The shape of the test images are:\", rawtest_X.shape)\n",
    "print(\"The shape of the test labels are:\", rawtest_y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYhQepjIjBsi",
    "outputId": "44e62616-fc90-4d4f-d6a3-53d48c0d75e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of the test images are: (10000, 28, 28)\n",
      "The shape of the test labels are: (10000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "np.unique(rawtrain_y) # the number of classes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs2uZxNAjJW8",
    "outputId": "0bb8e481-66ab-44e3-e7a5-fe2030855eff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "TT2BhqdfjA_o",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_X = rawtrain_X.reshape(rawtrain_X.shape[0], rawtrain_X.shape[1] * rawtrain_X.shape[2])\n",
    "test_X = rawtest_X.reshape(rawtest_X.shape[0], rawtest_X.shape[1] * rawtest_X.shape[2])"
   ],
   "metadata": {
    "id": "jsa_vEaRjMwV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_y = to_categorical(rawtrain_y, num_classes=10)\n",
    "test_y = to_categorical(rawtest_y, num_classes=10)"
   ],
   "metadata": {
    "id": "uDunK-U_jO61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#CNN"
   ],
   "metadata": {
    "id": "ZyPDlBR-jf_B",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ],
   "metadata": {
    "id": "BoGNQnVfjib-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##First determine the best batch size for our datasets(choose from 128,64,32)"
   ],
   "metadata": {
    "id": "jGDWnoajGwl1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X = rawtrain_X.reshape(-1,28,28,1)\n",
    "test_X = rawtest_X.reshape(-1,28,28,1)\n",
    "#normalize the data\n",
    "train_X = train_X/255\n",
    "test_X = test_X/255\n"
   ],
   "metadata": {
    "id": "crkiq5h2Gv-w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 30\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "#evaluation on the test set\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXSZGrF2E0SE",
    "outputId": "ad0bf8fb-2f88-42be-ad40-cfae451d5cdc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "469/469 [==============================] - 65s 137ms/step - loss: 0.5019 - accuracy: 0.8176\n",
      "Epoch 2/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.3158 - accuracy: 0.8857\n",
      "Epoch 3/30\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.2609 - accuracy: 0.9039\n",
      "Epoch 4/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.2331 - accuracy: 0.9146\n",
      "Epoch 5/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.2091 - accuracy: 0.9227\n",
      "Epoch 6/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.1890 - accuracy: 0.9302\n",
      "Epoch 7/30\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.1709 - accuracy: 0.9366\n",
      "Epoch 8/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.1536 - accuracy: 0.9434\n",
      "Epoch 9/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1367 - accuracy: 0.9493\n",
      "Epoch 10/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.1225 - accuracy: 0.9542\n",
      "Epoch 11/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.1052 - accuracy: 0.9609\n",
      "Epoch 12/30\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0954 - accuracy: 0.9650\n",
      "Epoch 13/30\n",
      "469/469 [==============================] - 63s 133ms/step - loss: 0.0821 - accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0697 - accuracy: 0.9734\n",
      "Epoch 15/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0603 - accuracy: 0.9782\n",
      "Epoch 16/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0510 - accuracy: 0.9817\n",
      "Epoch 17/30\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0479 - accuracy: 0.9821\n",
      "Epoch 18/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0409 - accuracy: 0.9857\n",
      "Epoch 19/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0380 - accuracy: 0.9865\n",
      "Epoch 20/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0339 - accuracy: 0.9871\n",
      "Epoch 21/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0297 - accuracy: 0.9887\n",
      "Epoch 22/30\n",
      "469/469 [==============================] - 64s 138ms/step - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 23/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0264 - accuracy: 0.9902\n",
      "Epoch 24/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 25/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0240 - accuracy: 0.9914\n",
      "Epoch 26/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 27/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 28/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0194 - accuracy: 0.9930\n",
      "Epoch 29/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0171 - accuracy: 0.9941\n",
      "Epoch 30/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0148 - accuracy: 0.9949\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_result_batch128 = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result_batch128[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aU13U-QtLFbR",
    "outputId": "593b05f2-c173-4fb5-fc0e-1c99e0a0874f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.5492 - accuracy: 0.9178\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9178000092506409"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 64\n",
    "epochs = 30\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3yGCjQ17WNo",
    "outputId": "dbd9c615-febe-4dc7-ca95-b45a27abd974",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 71s 75ms/step - loss: 0.4382 - accuracy: 0.8406\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 72s 77ms/step - loss: 0.2789 - accuracy: 0.8971\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 72s 77ms/step - loss: 0.2342 - accuracy: 0.9129\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 72s 76ms/step - loss: 0.2054 - accuracy: 0.9238\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.1787 - accuracy: 0.9341\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 71s 76ms/step - loss: 0.1567 - accuracy: 0.9429\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 71s 76ms/step - loss: 0.1357 - accuracy: 0.9488\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 72s 77ms/step - loss: 0.1184 - accuracy: 0.9555\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 70s 74ms/step - loss: 0.1019 - accuracy: 0.9622\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 68s 73ms/step - loss: 0.0836 - accuracy: 0.9691\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 71s 76ms/step - loss: 0.0738 - accuracy: 0.9715\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 70s 75ms/step - loss: 0.0618 - accuracy: 0.9776\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 71s 76ms/step - loss: 0.0533 - accuracy: 0.9797\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 70s 74ms/step - loss: 0.0458 - accuracy: 0.9828\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 69s 74ms/step - loss: 0.0453 - accuracy: 0.9831\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 70s 75ms/step - loss: 0.0347 - accuracy: 0.9873\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 69s 73ms/step - loss: 0.0330 - accuracy: 0.9881\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 68s 73ms/step - loss: 0.0338 - accuracy: 0.9875\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 68s 72ms/step - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 68s 72ms/step - loss: 0.0252 - accuracy: 0.9907\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 67s 72ms/step - loss: 0.0284 - accuracy: 0.9897\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 66s 70ms/step - loss: 0.0206 - accuracy: 0.9923\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 65s 69ms/step - loss: 0.0243 - accuracy: 0.9911\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 67s 72ms/step - loss: 0.0217 - accuracy: 0.9921\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0228 - accuracy: 0.9920\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 69s 74ms/step - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 73s 78ms/step - loss: 0.0210 - accuracy: 0.9926\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 68s 73ms/step - loss: 0.0167 - accuracy: 0.9941\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 68s 73ms/step - loss: 0.0207 - accuracy: 0.9929\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 68s 72ms/step - loss: 0.0188 - accuracy: 0.9930\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_result_batch64 = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result_batch64[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIFz8XVb1SQM",
    "outputId": "ce3145c9-902b-4d80-812d-87a45c72a2c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6436 - accuracy: 0.9172\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9172000288963318"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 32\n",
    "epochs = 30\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riV2LUQUHPNa",
    "outputId": "b30904cd-7ebd-4c71-acea-92246b0596e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.4205 - accuracy: 0.8453\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.2714 - accuracy: 0.9003\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.2246 - accuracy: 0.9165\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.1941 - accuracy: 0.9280\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.1689 - accuracy: 0.9366\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 76s 41ms/step - loss: 0.1454 - accuracy: 0.9456\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 74s 40ms/step - loss: 0.1274 - accuracy: 0.9524\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.1105 - accuracy: 0.9583\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0937 - accuracy: 0.9654\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0833 - accuracy: 0.9687\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0736 - accuracy: 0.9722\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0663 - accuracy: 0.9748\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0579 - accuracy: 0.9785\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0517 - accuracy: 0.9804\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0448 - accuracy: 0.9833\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0431 - accuracy: 0.9843\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0401 - accuracy: 0.9854\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0375 - accuracy: 0.9857\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0361 - accuracy: 0.9869\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0319 - accuracy: 0.9888\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 74s 40ms/step - loss: 0.0306 - accuracy: 0.9888\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0296 - accuracy: 0.9897\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0279 - accuracy: 0.9901\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 72s 39ms/step - loss: 0.0254 - accuracy: 0.9914\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 78s 42ms/step - loss: 0.0260 - accuracy: 0.9905\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 78s 42ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0247 - accuracy: 0.9919\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 78s 41ms/step - loss: 0.0222 - accuracy: 0.9928\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_result_batch32 = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result_batch32[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MEfMWqZHM6T",
    "outputId": "20193a17-f3ca-4b90-a476-5bc354753117",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6367 - accuracy: 0.9141\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9140999913215637"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## choose the best batch size 128 and then test on different epochs 10 to 50"
   ],
   "metadata": {
    "id": "rqSqBXoKkNnc",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 10\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kG79hb1FkNDS",
    "outputId": "a2fd0938-6203-4576-b323-62e13143c5e9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.4970 - accuracy: 0.8203\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.3122 - accuracy: 0.8873\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.2669 - accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.2383 - accuracy: 0.9129\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.2148 - accuracy: 0.9204\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.1939 - accuracy: 0.9277\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1760 - accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1601 - accuracy: 0.9398\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.1459 - accuracy: 0.9454\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.1303 - accuracy: 0.9510\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2619 - accuracy: 0.9113\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.911300003528595"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MArrkKEMk98O",
    "outputId": "b2fe01c7-6c18-47b4-d465-c2b52bea6001",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 72s 152ms/step - loss: 0.5069 - accuracy: 0.8162\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.3115 - accuracy: 0.8878\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.2639 - accuracy: 0.9041\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.2325 - accuracy: 0.9149\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.2086 - accuracy: 0.9231\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.1905 - accuracy: 0.9296\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.1687 - accuracy: 0.9379\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.1532 - accuracy: 0.9435\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.1353 - accuracy: 0.9494\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.1208 - accuracy: 0.9540\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1066 - accuracy: 0.9609\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0928 - accuracy: 0.9653\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0818 - accuracy: 0.9693\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.0701 - accuracy: 0.9743\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.0616 - accuracy: 0.9772\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0528 - accuracy: 0.9804\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0446 - accuracy: 0.9834\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0440 - accuracy: 0.9834\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0365 - accuracy: 0.9864\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0326 - accuracy: 0.9880\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4060 - accuracy: 0.9203\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9203000068664551"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 30\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go6FqxOyk_UZ",
    "outputId": "3c049ed5-4204-44dc-dbe8-c50a172e44fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.4995 - accuracy: 0.8179\n",
      "Epoch 2/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.3102 - accuracy: 0.8877\n",
      "Epoch 3/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.2630 - accuracy: 0.9043\n",
      "Epoch 4/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.2300 - accuracy: 0.9150\n",
      "Epoch 5/30\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.2067 - accuracy: 0.9231\n",
      "Epoch 6/30\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.1855 - accuracy: 0.9303\n",
      "Epoch 7/30\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.1671 - accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.1505 - accuracy: 0.9437\n",
      "Epoch 9/30\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.1361 - accuracy: 0.9495\n",
      "Epoch 10/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.1183 - accuracy: 0.9556\n",
      "Epoch 11/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.1063 - accuracy: 0.9607\n",
      "Epoch 12/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0941 - accuracy: 0.9647\n",
      "Epoch 13/30\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0795 - accuracy: 0.9700\n",
      "Epoch 14/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0733 - accuracy: 0.9724\n",
      "Epoch 15/30\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0630 - accuracy: 0.9764\n",
      "Epoch 16/30\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0540 - accuracy: 0.9802\n",
      "Epoch 17/30\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0482 - accuracy: 0.9821\n",
      "Epoch 18/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0433 - accuracy: 0.9840\n",
      "Epoch 19/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0377 - accuracy: 0.9861\n",
      "Epoch 20/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0357 - accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "469/469 [==============================] - 64s 138ms/step - loss: 0.0335 - accuracy: 0.9876\n",
      "Epoch 22/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0249 - accuracy: 0.9910\n",
      "Epoch 23/30\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 24/30\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0241 - accuracy: 0.9914\n",
      "Epoch 25/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 26/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0211 - accuracy: 0.9924\n",
      "Epoch 27/30\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0219 - accuracy: 0.9921\n",
      "Epoch 28/30\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 29/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0180 - accuracy: 0.9937\n",
      "Epoch 30/30\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0177 - accuracy: 0.9937\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6145 - accuracy: 0.9120\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9120000004768372"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 40\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYKP8pyElGhB",
    "outputId": "28ffac9f-9c9d-4c5c-a9e3-f4f374c96446",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - 68s 143ms/step - loss: 0.5034 - accuracy: 0.8189\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.3152 - accuracy: 0.8871\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.2659 - accuracy: 0.9039\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.2341 - accuracy: 0.9142\n",
      "Epoch 5/40\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.2062 - accuracy: 0.9252\n",
      "Epoch 6/40\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1879 - accuracy: 0.9310\n",
      "Epoch 7/40\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.1707 - accuracy: 0.9363\n",
      "Epoch 8/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.1554 - accuracy: 0.9419\n",
      "Epoch 9/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.1370 - accuracy: 0.9492\n",
      "Epoch 10/40\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.1243 - accuracy: 0.9544\n",
      "Epoch 11/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.1066 - accuracy: 0.9604\n",
      "Epoch 12/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0937 - accuracy: 0.9654\n",
      "Epoch 13/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0825 - accuracy: 0.9691\n",
      "Epoch 14/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0698 - accuracy: 0.9738\n",
      "Epoch 15/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0605 - accuracy: 0.9781\n",
      "Epoch 16/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0517 - accuracy: 0.9806\n",
      "Epoch 17/40\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0462 - accuracy: 0.9832\n",
      "Epoch 18/40\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0416 - accuracy: 0.9850\n",
      "Epoch 19/40\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0333 - accuracy: 0.9877\n",
      "Epoch 20/40\n",
      "469/469 [==============================] - 64s 138ms/step - loss: 0.0336 - accuracy: 0.9876\n",
      "Epoch 21/40\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0270 - accuracy: 0.9898\n",
      "Epoch 22/40\n",
      "469/469 [==============================] - 64s 138ms/step - loss: 0.0264 - accuracy: 0.9903\n",
      "Epoch 23/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0271 - accuracy: 0.9899\n",
      "Epoch 24/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0257 - accuracy: 0.9906\n",
      "Epoch 25/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0183 - accuracy: 0.9931\n",
      "Epoch 26/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0239 - accuracy: 0.9913\n",
      "Epoch 27/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 28/40\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0187 - accuracy: 0.9937\n",
      "Epoch 29/40\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0151 - accuracy: 0.9946\n",
      "Epoch 30/40\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 0.0216 - accuracy: 0.9919\n",
      "Epoch 31/40\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 32/40\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 33/40\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0142 - accuracy: 0.9952\n",
      "Epoch 34/40\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0167 - accuracy: 0.9940\n",
      "Epoch 35/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0171 - accuracy: 0.9943\n",
      "Epoch 36/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0149 - accuracy: 0.9948\n",
      "Epoch 37/40\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 38/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 39/40\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 40/40\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.5973 - accuracy: 0.9142\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9142000079154968"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 50\n",
    "#train the data on max pooling CNN\n",
    "model_train = model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = model.evaluate(test_X,test_y,verbose=1)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEMNogwRlTfr",
    "outputId": "2e315b05-ca0b-4a36-dec8-454d0ee13299",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 0.4994 - accuracy: 0.8196\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.3050 - accuracy: 0.8903\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.2590 - accuracy: 0.9049\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.2285 - accuracy: 0.9153\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.2027 - accuracy: 0.9247\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.1800 - accuracy: 0.9331\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.1624 - accuracy: 0.9388\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1470 - accuracy: 0.9445\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.1280 - accuracy: 0.9521\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.1158 - accuracy: 0.9570\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0987 - accuracy: 0.9640\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 0.0882 - accuracy: 0.9677\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0759 - accuracy: 0.9726\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0665 - accuracy: 0.9757\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0568 - accuracy: 0.9793\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0491 - accuracy: 0.9818\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0416 - accuracy: 0.9847\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0397 - accuracy: 0.9853\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0324 - accuracy: 0.9880\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0333 - accuracy: 0.9880\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0279 - accuracy: 0.9900\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0235 - accuracy: 0.9915\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 0.0263 - accuracy: 0.9906\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.0205 - accuracy: 0.9926\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.0258 - accuracy: 0.9901\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.0195 - accuracy: 0.9928\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.0192 - accuracy: 0.9931\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 61s 131ms/step - loss: 0.0109 - accuracy: 0.9961\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.0151 - accuracy: 0.9948\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.0106 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0107 - accuracy: 0.9960\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 0.0158 - accuracy: 0.9948\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0131 - accuracy: 0.9954\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.0113 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.0080 - accuracy: 0.9974\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 62s 131ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.7451 - accuracy: 0.9096\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.909600019454956"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 128 batch size with 20 epochs"
   ],
   "metadata": {
    "id": "NNplLkNa1bBT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#now test for adjusting our model in order to get a best performance model\n",
    "#add drop out regularization to our model\n",
    "from keras.layers import Dropout"
   ],
   "metadata": {
    "id": "3a_G9THc1H8l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "model.add(layers.MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "#flatten\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tcdafxhe1yUw",
    "outputId": "7b50bb32-b344-43bf-cfbc-c61a81bf3aeb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 438,154\n",
      "Trainable params: 438,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#regular model\n",
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KnKwP3q36le",
    "outputId": "bf6212b8-391b-4ea1-c517-9caf66cda69f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.4885 - accuracy: 0.8263\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 65s 140ms/step - loss: 0.3038 - accuracy: 0.8897\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.2588 - accuracy: 0.9049\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.2266 - accuracy: 0.9153\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.2074 - accuracy: 0.9230\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.1840 - accuracy: 0.9320\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.1663 - accuracy: 0.9378\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.1502 - accuracy: 0.9437\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.1336 - accuracy: 0.9503\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.1172 - accuracy: 0.9564\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.1026 - accuracy: 0.9617\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0898 - accuracy: 0.9671\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0778 - accuracy: 0.9709\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0667 - accuracy: 0.9757\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0579 - accuracy: 0.9786\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0520 - accuracy: 0.9816\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0445 - accuracy: 0.9837\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0364 - accuracy: 0.9869\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0366 - accuracy: 0.9865\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0376 - accuracy: 0.9859\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9175999760627747"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#regular model\n",
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.25))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,batch_size=128)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BL5thTu45Kl0",
    "outputId": "e7c835b3-59fa-4760-8288-99966b22729d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.5458 - accuracy: 0.8031\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.3418 - accuracy: 0.8765\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.2941 - accuracy: 0.8929\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.2619 - accuracy: 0.9039\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.2366 - accuracy: 0.9127\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.2211 - accuracy: 0.9181\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.2023 - accuracy: 0.9246\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1884 - accuracy: 0.9304\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1756 - accuracy: 0.9344\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1635 - accuracy: 0.9395\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.1530 - accuracy: 0.9419\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1398 - accuracy: 0.9459\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1310 - accuracy: 0.9499\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1218 - accuracy: 0.9535\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.1155 - accuracy: 0.9562\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1083 - accuracy: 0.9590\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1016 - accuracy: 0.9609\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0948 - accuracy: 0.9630\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0904 - accuracy: 0.9662\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0805 - accuracy: 0.9695\n",
      "79/79 [==============================] - 3s 40ms/step - loss: 0.2537 - accuracy: 0.9244\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9243999719619751"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_result = final_model.evaluate(test_X,test_y)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6m_DW8FIwBw",
    "outputId": "bb1be226-4575-4bba-a04f-cfda01bcf89d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2537 - accuracy: 0.9244\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9243999719619751"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#save the model for future use and loading\n",
    "final_model.save(\"DROPOUTmodel\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hs6eKrlyMaXz",
    "outputId": "d866f376-929a-4475-f9aa-245c8090bf9b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: DROPOUTmodel/assets\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_result = final_model.evaluate(test_X,test_y)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JR0Y5tpNMGD",
    "outputId": "68fe792b-1adb-4928-8fef-c06070cda947",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2296 - accuracy: 0.9187\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9186999797821045"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "reconstructed_model = keras.models.load_model(\"DROPOUTmodel\")"
   ],
   "metadata": {
    "id": "8yAbV2UWNQKy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_result = reconstructed_model.evaluate(test_X,test_y)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-vkgTinNdTh",
    "outputId": "3bf267d9-fd4f-4d04-ea86-2a193af49378",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2539 - accuracy: 0.9264\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9264000058174133"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## hyperparameter different kernal size"
   ],
   "metadata": {
    "id": "b56jH-UNbuVW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#now we can test for different hyperparameter\n",
    "#for this lab I am going to test for different kernal size and how it influence the test acc"
   ],
   "metadata": {
    "id": "FD-tMxvGNjvO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(5,5),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(5,5),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.25))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ATSAutYVgUu",
    "outputId": "d36f8c98-e472-4f2e-b618-573c7875471b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 144s 305ms/step - loss: 0.5281 - accuracy: 0.8110\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.3224 - accuracy: 0.8843\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 0.2769 - accuracy: 0.8992\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 140s 299ms/step - loss: 0.2456 - accuracy: 0.9101\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 142s 304ms/step - loss: 0.2245 - accuracy: 0.9164\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 142s 302ms/step - loss: 0.2063 - accuracy: 0.9232\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 0.1908 - accuracy: 0.9292\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 0.1793 - accuracy: 0.9331\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.1645 - accuracy: 0.9388\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.1520 - accuracy: 0.9428\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 0.1436 - accuracy: 0.9456\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 142s 302ms/step - loss: 0.1341 - accuracy: 0.9491\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 143s 304ms/step - loss: 0.1242 - accuracy: 0.9534\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.1164 - accuracy: 0.9559\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 0.1108 - accuracy: 0.9584\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 0.1037 - accuracy: 0.9601\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 140s 300ms/step - loss: 0.0960 - accuracy: 0.9628\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 142s 302ms/step - loss: 0.0893 - accuracy: 0.9653\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.0867 - accuracy: 0.9666\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 141s 302ms/step - loss: 0.0780 - accuracy: 0.9700\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9215999841690063"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.25))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnYRgRQoVj1a",
    "outputId": "aaf8b950-24bc-42fa-842e-7b16d7626d14",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.5285 - accuracy: 0.8091\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.3313 - accuracy: 0.8803\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.2896 - accuracy: 0.8944\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.2584 - accuracy: 0.9051\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.2410 - accuracy: 0.9104\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.2180 - accuracy: 0.9179\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.2048 - accuracy: 0.9240\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.1888 - accuracy: 0.9299\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1748 - accuracy: 0.9332\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1643 - accuracy: 0.9380\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1511 - accuracy: 0.9442\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1426 - accuracy: 0.9460\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 70s 148ms/step - loss: 0.1348 - accuracy: 0.9486\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1250 - accuracy: 0.9524\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1150 - accuracy: 0.9564\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 0.1072 - accuracy: 0.9594\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.0989 - accuracy: 0.9622\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.0940 - accuracy: 0.9634\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.0864 - accuracy: 0.9675\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 70s 148ms/step - loss: 0.0812 - accuracy: 0.9690\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9269000291824341"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(7,7),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(7,7),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.25))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl8ktzAqzypH",
    "outputId": "8e70a390-c8eb-48bd-ba11-293c796b5eee",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 246s 523ms/step - loss: 0.5492 - accuracy: 0.7975\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 245s 522ms/step - loss: 0.3341 - accuracy: 0.8795\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 244s 520ms/step - loss: 0.2861 - accuracy: 0.8954\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 244s 521ms/step - loss: 0.2569 - accuracy: 0.9052\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 243s 519ms/step - loss: 0.2332 - accuracy: 0.9134\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 245s 523ms/step - loss: 0.2145 - accuracy: 0.9199\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 243s 519ms/step - loss: 0.2012 - accuracy: 0.9254\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 243s 518ms/step - loss: 0.1831 - accuracy: 0.9319\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 243s 519ms/step - loss: 0.1721 - accuracy: 0.9343\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 243s 518ms/step - loss: 0.1632 - accuracy: 0.9377\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 242s 517ms/step - loss: 0.1498 - accuracy: 0.9428\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 243s 518ms/step - loss: 0.1413 - accuracy: 0.9456\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 245s 523ms/step - loss: 0.1325 - accuracy: 0.9494\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 243s 519ms/step - loss: 0.1261 - accuracy: 0.9520\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 245s 523ms/step - loss: 0.1154 - accuracy: 0.9558\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 242s 517ms/step - loss: 0.1078 - accuracy: 0.9588\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 243s 518ms/step - loss: 0.1046 - accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 243s 518ms/step - loss: 0.0985 - accuracy: 0.9619\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 245s 522ms/step - loss: 0.0932 - accuracy: 0.9640\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 246s 524ms/step - loss: 0.0866 - accuracy: 0.9675\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9218000173568726"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "f56QXcEyz2BJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##different dropout rate"
   ],
   "metadata": {
    "id": "bolKuniXRMaT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.25))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "id": "Yu8ZgaH8RPea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.5))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.5))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k1_nT98RQ4m",
    "outputId": "21fd6957-f522-4b14-98cc-c1bb3936862a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 72s 151ms/step - loss: 0.6081 - accuracy: 0.7805\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.3810 - accuracy: 0.8653\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.3291 - accuracy: 0.8814\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.2977 - accuracy: 0.8925\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.2759 - accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.2576 - accuracy: 0.9050\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 0.2419 - accuracy: 0.9129\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.2293 - accuracy: 0.9170\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.2194 - accuracy: 0.9194\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.2105 - accuracy: 0.9232\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.2004 - accuracy: 0.9267\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.1918 - accuracy: 0.9285\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.1850 - accuracy: 0.9315\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.1794 - accuracy: 0.9328\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 70s 148ms/step - loss: 0.1734 - accuracy: 0.9358\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1679 - accuracy: 0.9369\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 70s 148ms/step - loss: 0.1590 - accuracy: 0.9409\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1538 - accuracy: 0.9424\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1501 - accuracy: 0.9443\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.1476 - accuracy: 0.9445\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9204999804496765"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = keras.models.Sequential()\n",
    "final_model.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model.add(layers.MaxPool2D(2,2))\n",
    "final_model.add(Dropout(0.75))\n",
    "#flatten\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(layers.Dense(128,activation='relu'))\n",
    "final_model.add(Dropout(0.75))\n",
    "final_model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train = final_model.fit(train_X, train_y, batch_size=batchSize,epochs=epochs)\n",
    "\n",
    "test_result = final_model.evaluate(test_X,test_y,verbose=0)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkDgD4edRV5M",
    "outputId": "9c72f88e-20e5-4960-f11e-e3b6243604c6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.8375 - accuracy: 0.6957\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.5248 - accuracy: 0.8184\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.4586 - accuracy: 0.8408\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.4162 - accuracy: 0.8554\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.3910 - accuracy: 0.8656\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.3662 - accuracy: 0.8733\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.3502 - accuracy: 0.8795\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.3372 - accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.3259 - accuracy: 0.8847\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.3185 - accuracy: 0.8888\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.3083 - accuracy: 0.8918\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.3001 - accuracy: 0.8946\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.2905 - accuracy: 0.8979\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.2856 - accuracy: 0.9003\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.2838 - accuracy: 0.8995\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.2777 - accuracy: 0.9021\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.2717 - accuracy: 0.9046\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.2643 - accuracy: 0.9072\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.2614 - accuracy: 0.9056\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.2550 - accuracy: 0.9092\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9186999797821045"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "DrxWqm3gflGy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final_model_1 = keras.models.Sequential()\n",
    "final_model_1.add(layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "#apply max pooling layers\n",
    "final_model_1.add(layers.MaxPool2D(2,2))\n",
    "final_model_1.add(layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "#apply max pooling layers\n",
    "final_model_1.add(layers.MaxPool2D(2,2))\n",
    "final_model_1.add(Dropout(0.25))\n",
    "#flatten\n",
    "final_model_1.add(layers.Flatten())\n",
    "final_model_1.add(layers.Dense(128,activation='relu'))\n",
    "final_model_1.add(layers.Dense(128,activation='relu'))\n",
    "final_model_1.add(Dropout(0.25))\n",
    "final_model_1.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "\n",
    "#compile the model \n",
    "final_model_1.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 128\n",
    "epochs = 20\n",
    "#train the data on max pooling CNN\n",
    "final_model_train_1 = final_model_1.fit(train_X, train_y, batch_size=batchSize,epochs=epochs,verbose=1)\n",
    "\n",
    "test_result = final_model_1.evaluate(test_X,test_y,batch_size=128)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlVY43QZ9T6-",
    "outputId": "3d73cec9-2150-4717-c13b-6a36f778ecb8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.5387 - accuracy: 0.8025\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.3390 - accuracy: 0.8774\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.2879 - accuracy: 0.8959\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.2599 - accuracy: 0.9055\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.2335 - accuracy: 0.9139\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.2187 - accuracy: 0.9186\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 0.2002 - accuracy: 0.9256\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.1856 - accuracy: 0.9303\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1746 - accuracy: 0.9344\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1597 - accuracy: 0.9400\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1509 - accuracy: 0.9426\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1386 - accuracy: 0.9470\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.1294 - accuracy: 0.9507\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.1217 - accuracy: 0.9541\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1135 - accuracy: 0.9565\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.1072 - accuracy: 0.9590\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.1020 - accuracy: 0.9611\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.0934 - accuracy: 0.9638\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.0875 - accuracy: 0.9666\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.0824 - accuracy: 0.9688\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.2671 - accuracy: 0.9248\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9247999787330627"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "reconstructed_model = keras.models.load_model(\"DROPOUTmodel\")\n",
    "test_result = reconstructed_model.evaluate(test_X,test_y)\n",
    "test_result[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67awTXGBzWMu",
    "outputId": "03e17a3b-e736-4010-9009-f58025efc96c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2537 - accuracy: 0.9244\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9243999719619751"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##plot the best model with training epochs"
   ],
   "metadata": {
    "id": "S4BvNj95Ikdd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_acc = [0.8025,0.8774,0.8959,0.9055,0.9139,0.9186,0.9256,0.9303,0.9344,0.9400,0.9426,0.9470,0.9507,0.9541,0.9565,0.9590,0.9611,0.9638,0.9666,0.9688]"
   ],
   "metadata": {
    "id": "owIsNTnF0NEG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#plot the graph\n",
    "x = list(range(1,21))\n",
    "train_acc\n",
    "plt.plot(x,train_acc)\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.title('Training accuracy with number epochs')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "6t0Ab2geJtYZ",
    "outputId": "f683326e-58c3-4e56-ca42-bee575933191",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training accuracy with number epochs')"
      ]
     },
     "metadata": {},
     "execution_count": 60
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xddf3H8de7SdOVpCvpTPeeFAiUvUepshGLgKAIKqKooOL4KQKKA7eIIjIFERxYECggWxlNobtpm5aWZrXpyuhO8vn9cU7aQ8i4SXNzMz7Px+M+cu4533PO547eT7/f7znfr8wM55xzLlZdEh2Ac8659sUTh3POuSbxxOGcc65JPHE455xrEk8czjnnmsQTh3POuSbxxNGJSXpG0hUtXdY1n6TjJa1sYPtISSYpuTXjioWk+yXdlug4WlL4Xo9NdBxtTZv78rmGSaqIPO0J7AGqwuefNbOHYz2WmZ0Vj7Ku+czsNWBCzXNJ64DPmNkLCQvKuVo8cbQzZpZas9zQj4qkZDOrbM3Y2iN/n9omSUlmVtV4SZcI3lTVQUg6SVK+pG9IKgbuk9RX0lOSSiRtC5ezIvu8LOkz4fKVkl6XdEdY9j1JZzWz7ChJr0oql/SCpDsl/bmeuBuLsZ+k+yQVhtufiGw7V9JCSWWS1kiaFa5fJ+m0SLmba84faeq5StL7wIvh+sclFUsqDWOfEtm/h6SfSVofbn89XPdvSV+s9XoWSzq/jtf5gKQbwuWhYQxfCJ+PkbRVUpeazzFc/xAwHHhSUoWkr0cOeamk9yVtlvTtut7b8Bj3h+//v8PP4y1JY2q9F8mR8rU/5/9K+oWk7ZLWSjomXL9B0qY6mi8zJD0fnusVSSMix54YbtsqaaWki2vFeZekpyXtAE6u47X0lvQnSUWSCiTdJimpVqy/DT+jXEmnRvYdImlueO48SVdHtiVJ+lb4HSqXtEDSsMipT5O0OnwP7pSkcL+x4WssDT+Hv9b3OXQ0njg6lkFAP2AEcA3B53tf+Hw4sAv4bQP7zwRWAhnAT4A/1fwjaWLZR4C3gf7AzcDlDZyzsRgfImiSmwIMAH4BIOlI4EHga0Af4ARgXQPnqe1EYBJwZvj8GWBceI53gGiT3x3A4cAxBO/v14Fq4AHgsppCkg4BhgL/ruN8rwAnRc69Noy55vlrZlYd3cHMLgfeB842s1Qz+0lk83EETVqnAt+VNKmB1zoH+D7QF8gDftBA2dpmAosJPstHgEeBI4CxBK/9t5JSI+UvBW4l+F4sJHwfJfUCng+PMSCM6XeSJkf2/UQYWxrweh2x3A9Uhuc+FDgD+EytWNeE5/4e8A9J/cJtjwL5wBDgIuCHkk4Jt30VuASYDaQDnwZ2Ro770fA1Twcu5sB35lbgOYL3NQv4TR0xd0xm5o92+iD4oTwtXD4J2At0b6D8DGBb5PnLBE1dAFcCeZFtPQEDBjWlLMGPfyXQM7L9z8CfY3xN+2MEBhP8QPeto9wfgF809r6Ez2+uOT8wMox1dAMx9AnL9CZIbLuAQ+oo1x3YBowLn98B/K6eY44Jy3YBfg98FsgPtz0AfDXyOeY38Fpq4s+KrHsbmFPPee8H7ok8nw3k1jpWcgPfidWRbdPC8gMj67YAMyLnejSyLZWg/20Y8HGC5Fj7M/xeZN8HG/hMBhL05/WIrLsEeCkSayGgWu/L5eH5q4C0yLbbgfvD5ZXAufWc14DjIs8fA24Klx8E7o5+Fp3l4TWOjqXEzHbXPJHUU9IfwiaWMuBVoE9N9b4OxTULZlbzP67UJpYdAmyNrAPYUF/AjcQ4LDzWtjp2HUbwv8vm2h9T2FTxo7CpoowDNZeM8NG9rnOF7/VfgcskdSH4IXuorpOZ2RpgB0FiPB54CiiUNIGgxvFKE+MvjizvpP7Pqalla9sYWd4FYGa110WPt/99NbMKYCvBd2IEMDNs7tkuaTtB7WRQXfvWYQTQFSiK7P8HgtpLjQILf9FD68Nz13wny2ttGxouN/Zdqu/9+zog4G1JyyR9uoFjdCieODqW2kMd30DQnDHTzNI50DRSX/NTSygC+knqGVk3rL7CNBzjhvBYferYbwPB/+LrsoOgFlRjUB1lou/VJ4BzgdMIahkjIzFsBnY3cK4HCH4ATwV2mtkb9ZSDIDlcBKSYWUH4/AqCpo6F9ewTz+Grd4R/G3uvmmL/Zx02YfUjqAlsAF4xsz6RR6qZfT6yb0OvdQNBjSMjsn+6mU2JlBlaq2l1eHjuQoLvUVqtbQWRY9f3+dbLzIrN7GozG0JQg/ydOsmlu544OrY0gv8Rbg/ber8X7xOa2XogB7hZUoqko4GzmxOjmRUR9D38TkEneldJNYnlT8CnJJ2qoFN5qKSJ4baFwJywfDbBj3VD0gh+lLYQ/Ij+MBJDNXAv8POwgzVJ0tGSuoXb3yBoTvsZ9dQ2Il4BriOoVUHQLHQd8LrVfwXRRmB0I8dtFjMrIfjxvCx8XZ+mGT+gtcyWdJykFII+gDfNbANBDWu8pMvDz6WrpCMa6ZuJxlpE0J/wM0np4Wc+RtKJkWIDgC+Fx/4YQR/W0+H5/wfcLqm7pOnAVQRNqAD3ALdKGqfAdEn9G4tJ0sd04EKObQSJr7qBXToMTxwd2y+BHgT/a34TeLaVznspcDTBD/FtBM05e+op21iMlwP7gFxgE/BlADN7G/gUQWd5KcGPcs0VPP/HgT6F7xN0yDbkQYKmiwJgeRhH1I3AEmA+QdPLj/ngv50HCdr/67xyLOIVgiRVkzheJ0hUr9a7R9AW/52weebGRo7fHFcTXGCwheAChP8d5PEeIUj+WwkuKLgMIGwmOoOgU7yQoPnnx0C3Jhz7k0AKwWe0DfgbQT9YjbcILnDYTNDJfpGZbQm3XUJQkywE/knQt1JzGfvPCfoungPKCP5T0iOGeI4A3lJwb9Vc4HozW9uE19Nu6YNNgs61vPAyxVwzi3uNJxEkfRK4xsyOS3QsnZWkKwk69f0zaAVe43AtLmyCGBM2J8wi6D94orH92qOwL+dagqtrnOsUPHG4eBhE0H5fAfwa+LyZvZvQiOJA0plACUE/RGPNYc51GN5U5Zxzrkm8xuGcc65J4jrIYdi+/SsgieDu1R/V2j6C4FLHTIKrMC4zs3xJJxMOLRGaSHBn7BOS7ie4Yao03HalmdV3DTwAGRkZNnLkyBZ4Rc4513ksWLBgs5ll1l4ft6aq8M7fVcDpBGPEzAcuMbPlkTKPA0+Z2QPhuDGfsmB8nuhx+hGMr5NlZjvDxPGUmf0t1liys7MtJyfnoF+Tc851JpIWmFl27fXxbKo6kmA8o7VmtpdgkLFza5WZTDg6KfBSHdshuHnrmVpDWDjnnEuQeCaOoXxw7Jl8DowNU2MRcEG4fD6QVscdm3OAv9Ra9wMFw1f/ouYO3tokXSMpR1JOSUlJ816Bc865D0l05/iNwImS3iXotyjgwGx2SBpMcEfuvMg+3yTo8ziCYBycb9R1YDO728yyzSw7M/NDTXTOOeeaKZ6d4wV8cHC7LA4MKgaAmRUS1jjCAdEuNLPtkSIXA/80s32RfYrCxT2S7iNIPs4551pJPGsc84FxCmaDSyFocpobLSApIxyOGoKaxL21jnEJtZqpwloI4SiY5wFL4xC7c865esQtcVgwj/N1BM1MK4DHzGyZpFsknRMWOwlYKWkVwUQt+2cmkzSSoMZSe56ChyUtIRh0LoNgED3nnHOtpFPcOe6X4zrnXNPVdzluXG8AdM4517oq9lSyZlMFqzdVsHpTOV88ZRyp3Vr2p94Th3POtUOlO/eRV1LO6o01SaKCvI3lFJbunz2arknivBlDmTQ4vUXP7YnDOefaKDNjy469rN5YQd6mcvI2HUgSJeUH5kbr3rULYzJTOXJUP8YNTGPsgFTGDUhleL+eJCe1fFe2Jw7nnGsjNpbtZuGG7SzO387i/FKWFpSybef+uxFI7ZbMmAGpnDg+k3EDUhk3MJVxA9IY2qcHXbqogSO3LE8czjmXANt37mVxfimL87ezKPy7sSyoRSR1ERMGpnHG5EGMH5S2P0kMSu9OcCdCYnnicM65ONu1t4qlhaUs2rB9f7JYt+XA8HujM3px9Oj+TM/qwyHDejN5cG96pCQlMOKGeeJwzrkWtKeyityicpYUlLIkv5RF+dtZvamCqurg1ofBvbszPas3H8sexoxhfZg6tDe9e3RNcNRN44nDOeeaKZoklhaUsqSglJXF5VSGSaJPz65Mz+rD6ZMHckhWH6YP682AtO4JjvrgeeJwzrkY7KmsYmVx+f5O6yUFpazaWM6+qgNJYtrQ3lx9wmimD+3N1KG9yerbo030SbQ0TxzOOVfL1h17WVNSwcri8jqTRO8eQZL4zPGjmTa0N9M6cJKoiycO51ynVFlVzYZtu1izqYK1mytYs2kHa0oqWFNS8YFLYGuSxFXHjWZ6VudLEnXxxOGc69DKd+9jbcmBpFCTINZt2bG/BgGQkZrC6MxUZk0dzJjMXozJTGXsgNROnyTq4onDOdchVFZV897mHSwvKmN5URkrispZWVy2/94ICO6PGNG/J2MyUzll0gDGZKaGj1706ZmSwOjbF08czrl2p2z3PnKLyllRVMbywjJWFJexsricPZXVQDBG07gBaRw7NoOxA1L3J4jh/XqSkpzoiU/bP08czrk2y8zI37YrSBBFZfv/bti6a3+Zvj27MnlIOpcfNYJJg9OZPCSdMZmpniDiyBOHc65NqNhTycricnLD2kNuUbBctrsSAAlG9e/F9KF9mHPEcCYNTmPy4N4MTO/mfRCtzBOHc65VVVUb67bs2J8YcsNkEa1FpHZLZsKgNM4+ZMj+WsTEQWn0TPGfrLbAPwXnXNxsqdhDbnHQFxHUJspZtfFAX0QXwejMVKZn9eHj2cOYMChIEH4lU9vmicM512KKS3fz5totvLl2C2+s3cL6yEB+GandmDQ4jU8ePWJ/ghg7IJXuXdvuYH6ubp44nHPNtqlsN2+s3cKba7fy5totvLd5BwDp3ZOZObo/l80cweQh6UwYlEZGarcER+taSlwTh6RZwK+AJOAeM/tRre0jgHuBTGArcJmZ5YfbqoAlYdH3zeyccP0o4FGgP7AAuNzM9sbzdTjnAiXlez5Qo1hbEiSKtG7JHDmqH5fOHM5Ro/szaXA6Sa04sZBrXXFLHJKSgDuB04F8YL6kuWa2PFLsDuBBM3tA0inA7cDl4bZdZjajjkP/GPiFmT0q6ffAVcBd8XodznVmWyr28NZ7W3ljTZAsVm+qAILO6yNG9mXOEcM4anR/pgzp7YmiE4lnjeNIIM/M1gJIehQ4F4gmjsnAV8Pll4AnGjqggt6yU4BPhKseAG7GE4dzLWL3vioWrN/Gq6tLeHXVZlYUlQHQMyWJ7JH9uOCwLI4e05+pQ9LjMpe1ax/imTiGAhsiz/OBmbXKLAIuIGjOOh9Ik9TfzLYA3SXlAJXAj8zsCYLmqe1mVhk55tA4vgbnOjQzI29TBa+u3syrq0p4670t7N5XTdckcfiIvtx4xniOHpPB9KzedPVE4UKJ7hy/EfitpCuBV4ECoCrcNsLMCiSNBl6UtAQojfXAkq4BrgEYPnx4iwbtXHu2bcdeXs/bzGurS3ht9WaKSncDMDqzF3OOGM7x4zKYObo/qd0S/fPg2qp4fjMKgGGR51nhuv3MrJCgxoGkVOBCM9sebisI/66V9DJwKPB3oI+k5LDW8aFjRo59N3A3QHZ2ttVVxrnOYG9lNe++v43XVm/m1dUlLCkoxSy48um4cRl8aVwmx43NYFi/nokO1bUT8Uwc84Fx4VVQBcAcDvRNACApA9hqZtXANwmusEJSX2Cnme0JyxwL/MTMTNJLwEUEV1ZdAfwrjq/BuXZp6469PLesmBdWbOKNNZvZsbeKpC7i0GF9+PKp4zl+fAaHZPXxDm3XLHFLHGZWKek6YB7B5bj3mtkySbcAOWY2FzgJuF2SETRVfSHcfRLwB0nVQBeCPo6aTvVvAI9Kug14F/hTvF6Dc+3JpvLdzFu2kWeXFvHm2q1UVRtZfXtw3qFDOX5cJkeP6U/vHl0THabrAGTW8VtxsrOzLScnJ9FhONfiikp38ezSYp5ZUsz89VsxC/oqZk8dzFnTBjF5cLoP3eGaTdICM8uuvd57v5xrZzZs3cmzS4t5emkR776/HYCJg9K4/tRxzJ42mHEDUj1ZuLjyxOFcO/De5h08vaSIZ5cWs6QguLhw6tB0vnbmBGZNHcSYzNQER+g6E08czrVBFXsqWV5YxhtrtvDM0iJyi8sBmDGsD9+aPZFZUwYzvL9fBeUSwxOHcwm2pWIPywrLWFZYxtLCUpYXlu0fLFCCI0b047sfncysqYMY0qdHgqN1zhOHc63GzCgs3c2ygtIwUQR/a27AAxjWrwdTBvfmwsOGMmVIb6Zl9fZRZV2b44nDuTjZtmMvr+VtDhJEQZAotu3cBwQTGI3JTGXmqH5MHdqbyUPSmTK4N717+uWyru3zxOFcC1u4YTsPvbGeJxcXsreympSkLowflMqZUwYxZUg6U4b2ZtKgdHqk+ARGrn3yxOFcC9i9r4q5iwr585vrWZxfSq+UJC7OzuJjhw9j0uB0UpJ9gEDXcXjicO4grNu8g4ffWs9jOfmU7trHuAGp3HLuFM4/dChp3b3ZyXVMnjica6KqauPF3E089OZ6Xl1VQnIXcebUQVx+1AhmjurnN9+5Ds8Th3Mx2lyxh7/O38Ajb71PwfZdDEzvxldOG8+cI4cxML17osNzrtV44nCuAWbGO+9v46E31vP0kmL2VlVzzJj+fOcjkzht8kCf3Mh1Sp44nKvDus07eGHFRv7xTgHLi8pI65bMJ2YO57KjhjN2QFqiw3MuoTxxOEfQb7FwwzaeX76JF1ZsJG9TBQCTB6fzg/Onct6MofTyGfGcAzxxuE5s595KXlu9mReWb+TF3E1s2bGX5C5i5uh+fOLI4Zw2aaCPB+VcHTxxuE5lY9lu/rMiqFW8nreZvZXVpHVP5uQJAzht8kBOHJ/pkx051whPHK5DMzNWFJXzwoqNvLBiI4vzgyHJh/XrwWUzR3DapAEcMaqfd3I71wSeOFyHY2Yszi9l7qJCnl1aTMH2XUjBkORfO3MCp08e6JMdOXcQPHG4DiNvUzlzFxYyd1Eh67bsJCWpCyeMz+BLp47l5IkDGJDm91o41xI8cbh2rWD7Lp5cVMi/FhayoqiMLoJjxmRw7UljOXPqIO+vcC4OPHG4dmdzxR6eXlLE3IWF5KzfBgTNUN87ezIfmT7YaxbOxVlcE4ekWcCvgCTgHjP7Ua3tI4B7gUxgK3CZmeVLmgHcBaQDVcAPzOyv4T73AycCpeFhrjSzhfF8HS7xynfvY96yjcxdVMh/8zZTVW2MH5jK186cwNnTh/hls861orglDklJwJ3A6UA+MF/SXDNbHil2B/CgmT0g6RTgduByYCfwSTNbLWkIsEDSPDPbHu73NTP7W7xid23DnsoqXlyxibmLCvlP7ib2VlaT1bcHnz1hNOfMGMLEQemJDtG5TimeNY4jgTwzWwsg6VHgXCCaOCYDXw2XXwKeADCzVTUFzKxQ0iaCWsl2XIe3r6qavy3I5zf/WU1h6W4yUlP4xJHDOfuQIRw2vI9fDeVcgsUzcQwFNkSe5wMza5VZBFxA0Jx1PpAmqb+ZbakpIOlIIAVYE9nvB5K+C/wHuMnM9tQ+uaRrgGsAhg8ffvCvxsVdVbXx5KJCfvnCKtZt2cmMYX34wfnTOH5cBsl+n4VzbUaiO8dvBH4r6UrgVaCAoE8DAEmDgYeAK8ysOlz9TaCYIJncDXwDuKX2gc3s7nA72dnZFr+X4A6WmTFv2UZ+/vxKVm2sYOKgNO75ZDanThrgtQvn2qB4Jo4CYFjkeVa4bj8zKySocSApFbiwph9DUjrwb+DbZvZmZJ+icHGPpPsIko9rh8yMV1dv5mfPrWRxfimjM3rxm0sO5SPTBtOliycM59qqeCaO+cA4SaMIEsYc4BPRApIygK1hbeKbBFdYISkF+CdBx/nfau0z2MyKFPxX9DxgaRxfg4uTt9/byh3zVvL2uq0M7dODn1w0nQsOHepNUs61A3FLHGZWKek6YB7B5bj3mtkySbcAOWY2FzgJuF2SETRVfSHc/WLgBKB/2IwFBy67fVhSJiBgIfC5eL0G1/IWbdjOHc+t5LXVmxmQ1o1bz53Cx48YTkqyJwzn2guZdfzm/+zsbMvJyUl0GJ3ayuJyfvbcSp5bvpG+Pbvy+ZPGcPlRI+mRkpTo0Jxz9ZC0wMyya69vtMYhaQFBE9IjZrYtHsG5jmvd5h384oVVzF1USGpKMl85bTyfPm4kad19KBDn2qtYmqo+DnyK4Aa+HOA+4DnrDFUV1yx7Kqt4eWUJcxcW8uyyYromic+eMIbPnjCavr1SEh2ec+4gNZo4zCwP+Lak/wM+SlD7qAqvaPqVmW2Nc4yuHaisquaNtVv2J4vy3ZX075XClceM5LMnjvbxo5zrQGLqHJc0naDWMRv4O/AwcBzwIjAjbtG5Ns3MeOf97Ty5qJCnFhexuWIPqd2SOXPKIM6ZMYRjx/T3q6Sc64Bi7ePYDvyJD96l/ZakY+MZnGubcovLmLuwkCcXF7Jh6y5Skrtw6sQBnHPIEE6eOIDuXb3D27mOLJYax8dqxpuqzcwuaOF4XBv1/padPLm4kH8tLGDVxgqSuohjx2Zw/anjOWPKQNK9s9u5TiOWxPEZST+J3NHdF7jBzL4T39Bcom3bsZcnFhYwd1Eh774fjC+ZPaIvt5w7hdnTBpOR2i3BETrnEiGWxHGWmX2r5omZbZM0G/DE0UGZGY8vyOeHT69g+859TBqczk1nTeSj0weT1dfnvXCus4slcSRJ6lbTtyGpB+D/1eyg8jZV8O1/LuGt97aSPaIvN58zhalDeyc6LOdcGxJL4ngY+E94+S0EV1c9EL+QXCLs3lfF717K465X1tAzJZkfXTCNi7OH+WCDzrkPieU+jh9LWgycGq661czmxTcs15peX72Z7zyxhHVbdnL+oUP59kcmef+Fc65eMd3HYWbPAM/EORbXyjZX7OG2p5bzxMJCRvbvyZ+vmslx4zISHZZzro2L5T6Oo4DfAJMIJk9KAnaYmU/43E5VVxuP5Wzg9mdy2bm3ki+dMpZrTx7r918452ISS43jtwRzaTwOZAOfBMbHMygXP6s2lvOtfywhZ/02jhzVjx+eP5WxA9ISHZZzrh2JtakqT1KSmVUB90l6l2DiJddO7NpbxW9eXM3dr64lrXsyP71oOhcdnuVTszrnmiyWxLEznJFvoaSfAEWAD0DUjry8chP/96+lbNi6i4sOz+JbsyfRz0epdc41UyyJ43KCRHEd8BWCecQvjGdQrmVsKt/NrU+t4MlFhYzO6MUjV8/kmDHe+e2cOzgNJg5JScAPzexSYDfw/VaJyh2055dv5Bt/X0zF7kq+ctp4PnfSaLole+e3c+7gNZg4zKxK0ghJKWa2t7WCcs23a28Vt/17OQ+/9T6TB6fzq2tmMG6gd34751pOLE1Va4H/SpoL7KhZaWY/j1tUrlmWFpRy/aPvsqZkB9ecMJobzhjvtQznXIuLJXGsCR9dAP+vaxtUXW3c8/pafjpvJf16pfiNfM65uIplyJFm92tImgX8iuCmwXvM7Ee1to8gmIo2E9gKXGZm+eG2KzgwAu9tZvZAuP5w4H6gB/A0cH1nnv+8uHQ3Nzy+kP/mbeGMyQP58YXTfV5v51xcxXLn+EvAh36YzeyURvZLAu4ETgfygfmS5prZ8kixO4AHzewBSacAtwOXS+oHfI/ghkMDFoT7bgPuAq4G3iJIHLPopMOhPLu0mJv+sZg9+6q5/YJpzDlimN+X4ZyLu1iaqm6MLHcnuBS3Mob9jgTyamYPlPQocC4QTRyTga+Gyy8BT4TLZwLPm9nWcN/ngVmSXgbSzezNcP2DwHl0ssSxc28ltz61nL+8vYFpQ3vzyzkzGJOZmuiwnHOdRCxNVQtqrfqvpLdjOPZQYEPkeT4ws1aZRcAFBM1Z5wNpkvrXs+/Q8JFfx/oPkXQNcA3A8OHDYwi3fVicv50vP7qQ97bs4HMnjuGrp48nJdnvx3TOtZ5Ymqr6RZ52AQ4HWmpmnxuB30q6EngVKACqWuLAZnY3cDdAdnZ2u+8Dqao27n51LT97biUZqd14+DN+M59zLjFiaapaQNDPIIImqveAq2LYr4DgLvMaWeG6/cyskKDGgaRU4EIz2y6pADip1r4vh/tnNXTMjqhw+y6++thC3ly7lbOmDuL2C6bRp6d3gDvnEiOWpqpRzTz2fGCcpFEEP+5zgE9EC0jKALaaWTXBoIn3hpvmAT+U1Dd8fgbwTTPbKqksHOr9LYKRen/TzPjahaeXFPHNfyxhX1U1P7loOh/zgQmdcwnWaOO4pC9I6hN53lfStY3tZ2aVBONbzQNWAI+Z2TJJt0g6Jyx2ErBS0ipgIPCDcN+twK0EyWc+cEtNRzlwLXAPkEdwf0mH7Ri/Y95Krn34HUb278m/v3Q8F2f7VVPOucRTY7dASFpoZjNqrXvXzA6Na2QtKDs723JychIdRpO8mLuRT9+fw8cOz+KHF0yja5J3gDvnWpekBWaWXXt9LL9GSYr8Nze8P8Mb2ONoY9lubnx8MZMGp3PreVM9aTjn2pRYOsefBf4q6Q/h88+G61wcVFUbX/nrwmDipUsO9elcnXNtTiyJ4xsE90N8Pnz+PEEfg4uD37+yhv+t2cKPL5zG2AF+U59zru2JJXH0AP5oZr+H/U1V3YCd8QysM1qwfhs/f34VH50+mIuzhzW+g3POJUAsjef/IUgeNXoAL8QnnM6rdNc+vvSXdxncuzs/vGCaXz3lnGuzYkkc3c2souZJuNwzfiF1PmbGt/65hOKy3fz6kkNJ79410SE551y9YkkcOyQdVvMkHNZ8V/xC6nwey9nAvxcXccMZ4zlseN/Gd3DOuQSKpY/jy8DjkgoJhh0ZBHw8rlF1Inmbyvne3GUcO7Y/nzthTKLDcc65RsUy5Mh8SROBCeGqlWa2L75hdQ6791Vx3SPv0jMlmV9cPIMuXSJwC9sAABdHSURBVLxfwznX9sVS44AgaUwmmI/jMEmY2YPxC6tzuP3pFeQWl3PflUcwIL17osNxzrmYxDKs+vcIxpSaTDDj3lnA64AnjoPw/PKNPPDGeq46bhQnTxyQ6HCccy5msXSOXwScChSb2aeAQ2i5+Tg6paLSXXztb4uYMiSdr8+a0PgOzjnXhsSSOHaFw55XSkoHNvHBeTZcE1RVG19+dCF7K6v5zSWH0i3ZhxRxzrUvsfRx5ITDqv+RYFKnCuCNuEbVgd35Uh5vvbeVOz52CKN9nnDnXDsUy1VVNXNv/F7Ss0C6mS2Ob1gdU866rfzyhVWcN2MIFx5W51TpzjnX5sV6VRUAZrYuTnF0eKU793H9owsZ1q8nt5431YcUcc61W01KHK55zIyb/rGYjWW7+fvnjyHNhxRxzrVjPkNQK3jk7fd5ZmkxXztzAocM69P4Ds4514bFch9HvzpWl/vd47FZtbGcW55czvHjMrj6+NGJDsc55w5aLDWOd4ASYBWwOlxeJ+mdcMBDV4/d+6r44iPvktY9mZ9dfIgPKeKc6xBiSRzPA7PNLMPM+hPcOf4UcC3wu3gG19798oXVrNxYzs8vnsGANB9SxDnXMcSSOI4ys3k1T8zsOeBoM3uTYCbAekmaJWmlpDxJN9WxfbiklyS9K2mxpNnh+kslLYw8qiXNCLe9HB6zZlubHa/jlVUlHD8ugxPGZyY6FOecazGxXFVVJOkbwKPh848DG8MpZKvr2yncfidwOpAPzJc018yWR4p9B3jMzO6SVDMW1kgzexh4ODzONOAJM1sY2e9SM8uJ7SUmxr6qavI2lXPieO/XcM51LLHUOD4BZAFPhI/h4bok4OIG9jsSyDOztWa2lyDxnFurjAHp4XJvoLCO41zCgaTVbqwt2cG+KmPS4LREh+Kccy0qljvHNwNfrGdzXgO7DgU2RJ7nAzNrlbkZeE7SF4FewGl1HOfjfDjh3CepCvg7cJuZWe2dJF0DXAMwfPjwBsKMj9ziMgAmDkpvpKRzzrUvjdY4JI2XdLek5yS9WPNoofNfAtxvZlnAbOAhSftjkjQT2GlmSyP7XGpm04Djw8fldR3YzO42s2wzy87MbP0+hhVF5XRNEqMze7X6uZ1zLp5i6eN4HPg9cA9Q1YRjF/DBUXSzwnVRVwGzAMzsDUndgQyCEXgB5gB/ie5gZgXh33JJjxA0ibW5uUFyi8sYOyCNrkl+j6VzrmOJJXFUmtldzTj2fGCcpFEECWMOQd9I1PsEc33cL2kSwQyDJQBhzeNigloF4bpkoI+ZbZbUFfgo8EIzYou73KJyjhnTP9FhOOdci4slcTwp6Vrgn8CempVmtrWhncysUtJ1wDyCjvR7zWyZpFuAHDObC9wA/FHSVwg6yq+M9FecAGwws7WRw3YD5oVJI4kgafwxlhfamrbt2Etx2W4mese4c64DiiVxXBH+/VpknQGNXmdqZk8TXGIbXffdyPJy4Nh69n0ZOKrWuh1Am79bPbe4HPCOcedcxxTLVVWjWiOQjmT/FVVe43DOdUD1Jg5Jp5jZi5IuqGu7mf0jfmG1byuKyujfK4XM1AZvrHfOuXapoRrHicCLwNl1bDPAE0c9covLmTQ43Sdrcs51SPUmDjP7Xvj3U60XTvtXVW2sLC7n8qNGJDoU55yLi1jm4+gGXAiMjJY3s1viF1b7tW7LDvZUVjNxsHeMO+c6pliuqvoXUAosIHI5rqtbblHNFVXeMe6c65hiSRxZZjYr7pF0ELnFZSR1EWMHpCY6FOeci4tYxsP4Xzi0uYvBiqJyRmf0onvXpESH4pxzcRFLjeM44EpJ7xE0VQkwM5se18jaqdziMg4d3jfRYTjnXNzEkjjOinsUHUTZ7n3kb9vFJUe2/jDuzjnXWhq6ATDdzMqA8laMp11bFQ414pM3Oec6soZqHI8QjD67gOCGv+jdbDGNVdXZrPAxqpxznUBDNwB+NPzrY1XFKLeojPTuyQzu3T3RoTjnXNzE0seBpL7AOIL5MgAws1fjFVR7lVtczkQfasQ518HFcuf4Z4DrCWbwW0gw1PkbwCnxDa19qQ6HGrnwsKGJDsU55+Iqlvs4rgeOANab2cnAocD2uEbVDhVs30XFnkofasQ51+HFkjh2m9luCMatMrNcYEJ8w2p/VhSFc3D4UCPOuQ4ulj6OfEl9gCeA5yVtA9bHN6z2Z0VRORKMH+iJwznXscUyA+D54eLNkl4CegPPxjWqdii3uIwR/XrSq1tM1xs451y71eCvnKQkYJmZTQQws1daJap2qGbyJuec6+ga7OMwsypgpaRmjaEhaZaklZLyJN1Ux/bhkl6S9K6kxZJmh+tHStolaWH4+H1kn8MlLQmP+Wu1gWtfd+6tZN2WHX7jn3OuU4ilXaUvsEzS28COmpVmdk5DO4W1lTuB04F8YL6kuWa2PFLsO8BjZnaXpMnA0wQTRgGsMbMZdRz6LuBq4K2w/CzgmRheR9ys2liBGUz0oUacc51ALInj/5p57COBPDNbCyDpUeBcIJo4DKj5b3pvoLChA0oaDKSb2Zvh8weB80hw4sgNr6ia5DUO51wnEMvluLPN7JXoA5gdw35DgQ2R5/nhuqibgcsk5RPUHr4Y2TYqbMJ6RdLxkWPmN3JMACRdIylHUk5JSUkM4TZfbnE5vVKSyOrbI67ncc65tiCWxHF6Hetaaqj1S4D7zSyLIBk9JKkLUAQMN7NDga8Cj0hq0n/nzexuM8s2s+zMzMwWCrduK4rKmDAojS5dEt7d4pxzcVdv4pD0eUlLgAlhx3XN4z1gcQzHLgCGRZ5nheuirgIeAzCzNwjGwsowsz1mtiVcvwBYA4wP989q5Jitysz2j1HlnHOdQUM1jkeAs4G54d+ax+FmdlkMx54PjJM0SlIKMCc8VtT7wKkAkiYRJI4SSZlh5zqSRhMMsLjWzIqAMklHhVdTfRL4V2wvNT6Ky3ZTumsfk/yOcedcJ9HQsOqlQClBc1KTmVmlpOuAeUAScK+ZLZN0C5BjZnOBG4A/SvoKQUf5lWZmkk4AbpG0D6gGPmdmW8NDXwvcD/Qg6BRPcMd4OAeH1zicc51EXG9zNrOnCTq9o+u+G1leDhxbx35/B/5ezzFzgKktG2nzrSgOrqia4DUO51wnEUvnuGtAblE5Q/v0IL1710SH4pxzrcITx0HKLS7zOcadc52KJ46DsKeyijUlPtSIc65z8cRxEPI2VVBVbT7UiHOuU/HEcRBW1FxR5TUO51wn4onjIOQWldEtuQsj+/dMdCjOOddqPHEchNzicsYPTCM5yd9G51zn4b94B8GvqHLOdUaeOJqppHwPmyv2ev+Gc67T8cTRTLnhHeN+RZVzrrPxxNFMuX5FlXOuk/LE0UwrissYmN6Nfr1SEh2Kc861Kk8czZRbVO61Dedcp+SJoxn2VVWTt6nC+zecc52SJ45meG/zDvZWVTPJaxzOuU7IE0czrCjyK6qcc52XJ45myC0up2uSGJ2RmuhQnHOu1XniaIbcojLGZKaSkuxvn3Ou8/FfvmbILS5nks8x7pzrpDxxNNH2nXspKt3NRJ9j3DnXSXniaKL9c3B4jcM510nFNXFImiVppaQ8STfVsX24pJckvStpsaTZ4frTJS2QtCT8e0pkn5fDYy4MHwPi+RpqqxmjapLXOJxznVRyvA4sKQm4EzgdyAfmS5prZssjxb4DPGZmd0maDDwNjAQ2A2ebWaGkqcA8YGhkv0vNLCdesTckt6icfr1SyEzrlojTO+dcwsWzxnEkkGdma81sL/AocG6tMgbUtPn0BgoBzOxdMysM1y8DekhqE7/UucVlTByUhqREh+KccwkRz8QxFNgQeZ7PB2sNADcDl0nKJ6htfLGO41wIvGNmeyLr7gubqf5P9fyCS7pGUo6knJKSkma/iKiqamPlRr+iyjnXuSW6c/wS4H4zywJmAw9J2h+TpCnAj4HPRva51MymAceHj8vrOrCZ3W1m2WaWnZmZ2SLBrt+yg937qv2KKudcpxbPxFEADIs8zwrXRV0FPAZgZm8A3YEMAElZwD+BT5rZmpodzKwg/FsOPELQJNYqcouDK6q8xuGc68zimTjmA+MkjZKUAswB5tYq8z5wKoCkSQSJo0RSH+DfwE1m9t+awpKSJdUklq7AR4GlcXwNH5BbVEYXwdgBPtSIc67zilviMLNK4DqCK6JWEFw9tUzSLZLOCYvdAFwtaRHwF+BKM7Nwv7HAd2tddtsNmCdpMbCQoAbzx3i9htpWFJczOjOV7l2TWuuUzjnX5sTtclwAM3uaoNM7uu67keXlwLF17HcbcFs9hz28JWNsitziMg7J6pOo0zvnXJuQ6M7xdqN89z42bN3l/RvOuU7PE0eMVm0MhxrxK6qcc52cJ44Y+RhVzjkX8MQRo9ziMtK6JzOkd/dEh+KccwnliSNGuUXlTBqU7kONOOc6PU8cMTAzcovLfY5x55zDE0dM8rftomJPJRMHef+Gc8554ojBiqJgDg6vcTjnnCeOmNSMUTVhoCcO55zzxBGD3OIyRvTvSa9ucb3R3jnn2gVPHDGouaLKOeecJ45G7dpbxXtbdnj/hnPOhTxxNGLVxnLM8CuqnHMu5ImjEbnFwRVVk7zG4ZxzgCeORq0oKqdnShLD+vZMdCjOOdcmeOJoRG5xGRMGpdGliw814pxz4ImjQfuHGvH+Deec288TRwM2lu1h+8593r/hnHMRnjgasCLsGPcah3POHeCJowG54eRNE3zWP+ec288TRwNyi8sY2qcHvXt0TXQozjnXZsQ1cUiaJWmlpDxJN9WxfbiklyS9K2mxpNmRbd8M91sp6cxYj9mSxg9M4+xDhsTzFM451+7EbdQ+SUnAncDpQD4wX9JcM1seKfYd4DEzu0vSZOBpYGS4PAeYAgwBXpA0PtynsWO2mC+cPDYeh3XOuXYtnjWOI4E8M1trZnuBR4Fza5UxoKbnuTdQGC6fCzxqZnvM7D0gLzxeLMd0zjkXR/FMHEOBDZHn+eG6qJuByyTlE9Q2vtjIvrEcEwBJ10jKkZRTUlLS3NfgnHOulkR3jl8C3G9mWcBs4CFJLRKTmd1tZtlmlp2ZmdkSh3TOOUcc+ziAAmBY5HlWuC7qKmAWgJm9Iak7kNHIvo0d0znnXBzFs8YxHxgnaZSkFILO7rm1yrwPnAogaRLQHSgJy82R1E3SKGAc8HaMx3TOORdHcatxmFmlpOuAeUAScK+ZLZN0C5BjZnOBG4A/SvoKQUf5lWZmwDJJjwHLgUrgC2ZWBVDXMeP1Gpxzzn2Ygt/pji07O9tycnISHYZzzrUrkhaYWXbt9YnuHHfOOdfOdIoah6QSYH2i46hHBrA50UE0wOM7OB7fwfH4Ds7BxjfCzD50WWqnSBxtmaScuqqCbYXHd3A8voPj8R2ceMXnTVXOOeeaxBOHc865JvHEkXh3JzqARnh8B8fjOzge38GJS3zex+Gcc65JvMbhnHOuSTxxOOecaxJPHK1A0rBwpsPlkpZJur6OMidJKpW0MHx8t5VjXCdpSXjuD91mr8Cvw5kXF0s6rBVjmxB5XxZKKpP05VplWvX9k3SvpE2SlkbW9ZP0vKTV4d++9ex7RVhmtaQrWjG+n0rKDT+/f0rqU8++DX4X4hjfzZIKIp/h7Hr2jfssoPXE99dIbOskLaxn39Z4/+r8TWm176CZ+SPOD2AwcFi4nAasAibXKnMS8FQCY1wHZDSwfTbwDCDgKOCtBMWZBBQT3JiUsPcPOAE4DFgaWfcT4KZw+Sbgx3Xs1w9YG/7tGy73baX4zgCSw+Uf1xVfLN+FOMZ3M3BjDJ//GmA0kAIsqv1vKV7x1dr+M+C7CXz/6vxNaa3voNc4WoGZFZnZO+FyObCCeiagasPOBR60wJtAH0mDExDHqcAaM0voSABm9iqwtdbqc4EHwuUHgPPq2PVM4Hkz22pm24DnCacWiHd8ZvacmVWGT98kmJYgIep5/2LRKrOANhSfJAEXA39p6fPGqoHflFb5DnriaGWSRgKHAm/VsfloSYskPSNpSqsGFoxO/JykBZKuqWN7zLMvxtkc6v8Hm8j3D2CgmRWFy8XAwDrKtJX38dMENci6NPZdiKfrwqa0e+tpZmkL79/xwEYzW13P9lZ9/2r9prTKd9ATRyuSlAr8HfiymZXV2vwOQfPLIcBvgCdaObzjzOww4CzgC5JOaOXzN0rBHCznAI/XsTnR798HWNAm0CavdZf0bYLpCh6up0iivgt3AWOAGUARQXNQW3QJDdc2Wu39a+g3JZ7fQU8crURSV4IP+GEz+0ft7WZWZmYV4fLTQFdJGa0Vn5kVhH83Af8kaBKIimVGx3g7C3jHzDbW3pDo9y+0sab5Lvy7qY4yCX0fJV0JfBS4NPxh+ZAYvgtxYWYbzazKzKqBP9Zz3kS/f8nABcBf6yvTWu9fPb8prfId9MTRCsI20T8BK8zs5/WUGRSWQ9KRBJ/NllaKr5ektJplgk7UpbWKzQU+GV5ddRRQGqkSt5Z6/6eXyPcvYi5Qc4XKFcC/6igzDzhDUt+wKeaMcF3cSZoFfB04x8x21lMmlu9CvOKL9pmdX895Ez0L6GlArpnl17Wxtd6/Bn5TWuc7GM+ef3/sv4rhOIIq42JgYfiYDXwO+FxY5jpgGcFVIm8Cx7RifKPD8y4KY/h2uD4an4A7Ca5oWQJkt/J72IsgEfSOrEvY+0eQwIqAfQRtxFcB/YH/AKuBF4B+Ydls4J7Ivp8G8sLHp1oxvjyCtu2a7+Dvw7JDgKcb+i60UnwPhd+txQQ/gINrxxc+n01wFdGa1owvXH9/zXcuUjYR7199vymt8h30IUecc841iTdVOeecaxJPHM4555rEE4dzzrkm8cThnHOuSTxxOOecaxJPHK7Dk9RH0rXN3Pfp+kaRjZS5RdJpzYuu9UgaGR3t1bnm8stxXYcXjuXzlJlNrWNbsh0Y+K9Da+h9cK4pvMbhOoMfAWPC+RF+qmDujtckzQWWA0h6IhyUbll0YLpwboWM8H/rKyT9MSzznKQeYZn7JV0UKf99Se+EczJMDNdnhvMjLJN0j6T1dQ2JIukMSW+E+z8ejkVUc9yfhMd8W9LYcP1ISS+GAwP+R9LwcP1ABXNuLAofx4SnSKrnNXxJwdwOiyU9GqfPwXUQnjhcZ3ATwVDsM8zsa+G6w4DrzWx8+PzTZnY4wR22X5LUv47jjAPuNLMpwHbgwnrOt9mCQe7uAm4M130PeDHc92/A8No7hYnkO8Bp4f45wFcjRUrNbBrwW+CX4brfAA+Y2XSCQQt/Ha7/NfCKBYM+HkZwF3NDr+Em4NDwOJ+r53U5B3jicJ3X22b2XuT5lyTVDFcyjOAHtrb3zKxm1rcFwMh6jv2POsocRzB3BGb2LLCtjv2OIpiM578KZpe7AhgR2f6XyN+jw+WjgUfC5YfC8wCcQpC4sGDgwNJGXsNi4GFJlxGMnOtcvZITHYBzCbKjZkHSSQSD1x1tZjslvQx0r2OfPZHlKqBHPcfeEynTlH9jIphg55J6tls9y01R32v4CMGsd2cD35Y0rbP0/bim8xqH6wzKCabXrE9vYFuYNCYS/M+/pf2XYNY4JJ1BMGVnbW8Cx0b6L3pJGh/Z/vHI3zfC5f8RjBALcCnwWrj8H+Dz4XGSJPWuLzBJXYBhZvYS8A2C9yO1Sa/OdSqeOFyHZ2ZbCJp/lkr6aR1FngWSJa0g6Eh/Mw5hfJ9gKOulwMcIZmcrrxVnCXAl8BdJiwmSw8RIkb7h+uuBr4Trvgh8Klx/ebiN8O/JkpYQNElNbiC2JODPYdl3gV+b2fbmvlDX8fnluM61AkndgCozq5R0NHCXmc1owv7rCIay3xyvGJ2LlfdxONc6hgOPhc1Ce4GrExyPc83mNQ7nnHNN4n0czjnnmsQTh3POuSbxxOGcc65JPHE455xrEk8czjnnmuT/AR4usdKztn4fAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}